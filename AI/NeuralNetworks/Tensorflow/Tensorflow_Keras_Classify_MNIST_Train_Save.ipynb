{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "def load_mnist_data(path='MNIST_data/'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    Train_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 'train')\n",
    "    Train_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 'train')\n",
    "    Test_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 't10k')\n",
    "    Test_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 't10k')\n",
    "    #open(images_path)\n",
    "    print(Train_labels_path)\n",
    "    print(type(Train_labels_path))\n",
    "    with open(Train_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_train_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(Test_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_test_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "    with open(Train_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_train_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_train_orig), 784)\n",
    "    with open(Test_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_test_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_test_orig), 784)\n",
    "\n",
    "    return X_train_orig, Y_train_orig, X_test_orig, Y_test_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/train-labels.idx1-ubyte\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_mnist_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 784)\n",
      "(1000, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(test_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 10, \n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷是 work\n",
      " 卷的序列号是 AE81-390C\n",
      "\n",
      " D:\\li\\python\\AI\\NeuralNetworks\\Tensorflow\\training_1 的目录\n",
      "\n",
      "2018/09/11  11:07    <DIR>          .\n",
      "2018/09/11  11:07    <DIR>          ..\n",
      "2018/09/11  11:07                71 checkpoint\n",
      "2018/09/11  11:07         1,631,720 cp.ckpt.data-00000-of-00001\n",
      "2018/09/11  11:07               647 cp.ckpt.index\n",
      "               3 个文件      1,632,438 字节\n",
      "               2 个目录 236,000,215,040 可用字节\n"
     ]
    }
   ],
   "source": [
    "!dir {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 110us/step\n",
      "Untrained model, accuracy: 14.90%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 39us/step\n",
      "Restored model, accuracy: 86.40%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss,acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.91742511e-05   9.87547874e-01   5.44766756e-03   3.93518858e-04\n",
      "    6.81851598e-05   7.72938292e-05   9.85181541e-04   3.83753399e-03\n",
      "    1.25377509e-03   3.69676738e-04]]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1645baec9b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADH9JREFUeJzt3X/sXXV9x/Hne6W0EySCWlZLB+gI\nWQVX59dqUuNwDAILG/iHxP5husRYkskyE/+Q8I/EZYYsijP74VJGY90EdUNsk+EmIVvQjDAKI/yw\nMgjpsLRpJaAgk0Lb9/74npov8L3n++29595zv7yfj+Sbe+75nHPPO7d9fT/n3M/53k9kJpLq+ZW+\nC5DUD8MvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqmoEyZ5sBNjRa7kpEkeUirlRV7gpTwUi9l2\npPBHxCXAl4FlwN9n5vVt26/kJN4XF45ySEkt7sk7F73t0Kf9EbEM+BvgUmAdsCki1g37epIma5Rr\n/g3A45n5RGa+BHwDuLybsiSN2yjhXwP8eM7zvc26V4iILRGxKyJ2vcyhEQ4nqUujhH++DxVe8/fB\nmbk1M2cyc2Y5K0Y4nKQujRL+vcDaOc/PAPaNVo6kSRkl/PcC50TE2RFxIvBRYGc3ZUkat6GH+jLz\ncERcDfwbs0N92zLzkc4qkzRWI43zZ+btwO0d1SJpgry9VyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeK\nMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiJjpFt+qJ\n97xzYNu/7PyH1n3P/7urW9vX/tl/DlWTZtnzS0UZfqkowy8VZfilogy/VJThl4oy/FJRI43zR8Qe\n4HngCHA4M2e6KEqvHwffe8rAtsMcad33Dfuy63I0Rxc3+XwoM5/u4HUkTZCn/VJRo4Y/ge9FxH0R\nsaWLgiRNxqin/Rszc19ErALuiIgfZeZdczdofilsAVjJG0Y8nKSujNTzZ+a+5vEgcBuwYZ5ttmbm\nTGbOLGfFKIeT1KGhwx8RJ0XEG48tAxcDD3dVmKTxGuW0/3Tgtog49jo3Z+a/dlKVpLEbOvyZ+QTw\nWx3WotehZ981eCx/7+FDrfu++aa7uy5HczjUJxVl+KWiDL9UlOGXijL8UlGGXyrKr+7WSHLj+tb2\n7192w8C237nrT1r3/Q3+e6iatDj2/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOP8Gskz6361tX31\nssFf3bbmn5d3XY6Ogz2/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxXlOL9GcuEft3+99ndeeNPAtpP/\n49HWfdsn8Nao7Pmlogy/VJThl4oy/FJRhl8qyvBLRRl+qagFx/kjYhtwGXAwM89r1p0GfBM4C9gD\nXJmZz46vTPVl2TvPbW3//KpbWttveu6MgW1HfvqzoWpSNxbT838VuORV664B7szMc4A7m+eSlpAF\nw5+ZdwHPvGr15cD2Znk7cEXHdUkas2Gv+U/PzP0AzeOq7kqSNAljv7c/IrYAWwBWMvj73CRN1rA9\n/4GIWA3QPB4ctGFmbs3MmcycWc6KIQ8nqWvDhn8nsLlZ3gzs6KYcSZOyYPgj4hbgbuDciNgbER8H\nrgcuiojHgIua55KWkAWv+TNz04CmCzuuRVPoqYvePNL+9z1/ZkvrL0Z6bY3GO/ykogy/VJThl4oy\n/FJRhl8qyvBLRfnV3Wr13LqXR9r/gb9eP7DtTbR/7bfGy55fKsrwS0UZfqkowy8VZfilogy/VJTh\nl4pynL+4Q5e+t7V9x8V/1dr+uaff09p+2q0PDmw72rqnxs2eXyrK8EtFGX6pKMMvFWX4paIMv1SU\n4ZeKcpy/uL2/2/5f4F0nrmxt37zn/Nb2VS/86Lhr0mTY80tFGX6pKMMvFWX4paIMv1SU4ZeKMvxS\nUQuO80fENuAy4GBmntesuw74BPCTZrNrM/P2cRWp8XnreQdb249k+1/dn7Dj1C7L0QQtpuf/KnDJ\nPOu/lJnrmx+DLy0xC4Y/M+8CnplALZImaJRr/qsj4sGI2BYRnvtJS8yw4f8K8A5gPbAf+OKgDSNi\nS0TsiohdL3NoyMNJ6tpQ4c/MA5l5JDOPAjcCG1q23ZqZM5k5s5wVw9YpqWNDhT8iVs95+mHg4W7K\nkTQpixnquwW4AHhLROwFPgtcEBHrgQT2AFeNsUZJY7Bg+DNz0zyrbxpDLRqDE84+s7X9C+f+U2v7\njT9b29p+2ra7j7smTQfv8JOKMvxSUYZfKsrwS0UZfqkowy8V5Vd3v849dtXbWtvfv8BNl5+4/0Ot\n7Wu9v2vJsueXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIc53+dO7r2xZH2/8VP26fo1tJlzy8VZfil\nogy/VJThl4oy/FJRhl8qyvBLRTnO/zr3t+/7x5H2X/PdZR1Vomljzy8VZfilogy/VJThl4oy/FJR\nhl8qyvBLRS04zh8Ra4GvAb8GHAW2ZuaXI+I04JvAWcAe4MrMfHZ8pWqQF/9gw8C2D6z8rwX29laP\nqhbT8x8GPp2Zvwm8H/hkRKwDrgHuzMxzgDub55KWiAXDn5n7M/P+Zvl5YDewBrgc2N5sth24YlxF\nSurecV3zR8RZwLuBe4DTM3M/zP6CAFZ1XZyk8Vl0+CPiZOBW4FOZ+dxx7LclInZFxK6XOTRMjZLG\nYFHhj4jlzAb/65n57Wb1gYhY3bSvBg7Ot29mbs3MmcycWc4Cs0JKmpgFwx8RAdwE7M7MG+Y07QQ2\nN8ubgR3dlydpXBYzzrMR+BjwUEQ80Ky7Frge+FZEfBx4EvjIeErUQp78wxzYtiLa/4k/9/T5re0n\n77ivtX3wkTXtFgx/Zv4AiAHNF3ZbjqRJ8Q4/qSjDLxVl+KWiDL9UlOGXijL8UlH+PecSsOyUU1rb\nP7Px9qFf++bvfrC1/e2H7x76tTXd7Pmlogy/VJThl4oy/FJRhl8qyvBLRRl+qSjH+ZeAo4fav/7s\nh//3toFtv/fUTOu+53z+kdb2I62tWsrs+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMf5l4BcYJz/\n0Zah/BP539Z9Hcevy55fKsrwS0UZfqkowy8VZfilogy/VJThl4paMPwRsTYi/j0idkfEIxHxp836\n6yLiqYh4oPn5/fGXK6kri7nJ5zDw6cy8PyLeCNwXEXc0bV/KzC+MrzxJ47Jg+DNzP7C/WX4+InYD\na8ZdmKTxOq5r/og4C3g3cE+z6uqIeDAitkXEqQP22RIRuyJi18u036YqaXIWHf6IOBm4FfhUZj4H\nfAV4B7Ce2TODL863X2ZuzcyZzJxZzooOSpbUhUWFPyKWMxv8r2fmtwEy80BmHsnMo8CNwIbxlSmp\na4v5tD+Am4DdmXnDnPWr52z2YeDh7suTNC6L+bR/I/Ax4KGIeKBZdy2wKSLWAwnsAa4aS4WSxmIx\nn/b/AIh5moafFF5S77zDTyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8V\nZfilogy/VFRk5uQOFvETeMWc0W8Bnp5YAcdnWmub1rrA2obVZW1nZuZbF7PhRMP/moNH7MrMltnl\n+zOttU1rXWBtw+qrNk/7paIMv1RU3+Hf2vPx20xrbdNaF1jbsHqprddrfkn96bvnl9STXsIfEZdE\nxKMR8XhEXNNHDYNExJ6IeKiZeXhXz7Vsi4iDEfHwnHWnRcQdEfFY8zjvNGk91TYVMze3zCzd63s3\nbTNeT/y0PyKWAf8DXATsBe4FNmXmDydayAARsQeYyczex4Qj4oPAz4GvZeZ5zbq/AJ7JzOubX5yn\nZuZnpqS264Cf9z1zczOhzOq5M0sDVwB/RI/vXUtdV9LD+9ZHz78BeDwzn8jMl4BvAJf3UMfUy8y7\ngGdetfpyYHuzvJ3Z/zwTN6C2qZCZ+zPz/mb5eeDYzNK9vnctdfWij/CvAX485/lepmvK7wS+FxH3\nRcSWvouZx+nNtOnHpk9f1XM9r7bgzM2T9KqZpafmvRtmxuuu9RH++Wb/maYhh42Z+dvApcAnm9Nb\nLc6iZm6elHlmlp4Kw8543bU+wr8XWDvn+RnAvh7qmFdm7mseDwK3MX2zDx84Nklq83iw53p+aZpm\nbp5vZmmm4L2bphmv+wj/vcA5EXF2RJwIfBTY2UMdrxERJzUfxBARJwEXM32zD+8ENjfLm4EdPdby\nCtMyc/OgmaXp+b2bthmve7nJpxnK+EtgGbAtM/984kXMIyLezmxvD7OTmN7cZ20RcQtwAbN/9XUA\n+CzwHeBbwK8DTwIfycyJf/A2oLYLmD11/eXMzceusSdc2weA7wMPAUeb1dcye33d23vXUtcmenjf\nvMNPKso7/KSiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFfX/7rNytWwRJ6EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1645b87d780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=2\n",
    "res = model.predict(test_images[index].reshape(1, 784))\n",
    "print(res)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.argmax(res, 1)))\n",
    "plt.imshow(test_images[index].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save entire model to a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the exact same model, including weights and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 126us/step\n",
      "Restored model, accuracy: 86.40%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
