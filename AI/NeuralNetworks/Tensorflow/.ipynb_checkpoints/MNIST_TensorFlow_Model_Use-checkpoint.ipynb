{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_layer=[784,16,16,10]\n",
    "parameters = initialize_parameters(network_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
      "Model restored.\n",
      "[[-0.07698201 -0.08336387 -0.07433794 ... -0.03583223  0.00852627\n",
      "   0.02142677]\n",
      " [ 0.06581955  0.0486571   0.02417413 ...  0.08421017  0.05880846\n",
      "  -0.07478838]\n",
      " [-0.03511408  0.07325806 -0.00935223 ...  0.04019384  0.06981052\n",
      "  -0.04618645]\n",
      " ...\n",
      " [-0.04202675 -0.00866584  0.07966198 ... -0.03028224 -0.08036571\n",
      "  -0.00710306]\n",
      " [-0.00700899  0.03899312 -0.0460798  ...  0.07146367  0.0320491\n",
      "   0.00994988]\n",
      " [ 0.05764115 -0.05095618  0.03379001 ...  0.05744845  0.02907361\n",
      "  -0.04694676]]\n",
      "[[ 0.23782471]\n",
      " [ 0.6917846 ]\n",
      " [-0.31217337]\n",
      " [ 0.27110642]\n",
      " [ 0.00490127]\n",
      " [ 0.28915295]\n",
      " [ 0.14158197]\n",
      " [-0.0988294 ]\n",
      " [-0.15552738]\n",
      " [-0.3880662 ]\n",
      " [-0.30541196]\n",
      " [-0.06743443]\n",
      " [ 0.13135508]\n",
      " [ 0.4248778 ]\n",
      " [ 0.22715396]\n",
      " [-0.386558  ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "           # Run the initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver.restore(sess, \"./saved_model/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    print(parameters['W1'].eval())\n",
    "    print(parameters['b1'].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3 }\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [X.shape[0], 1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "def load_mnist_data(path='MNIST_data/'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    Train_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 'train')\n",
    "    Train_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 'train')\n",
    "    Test_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 't10k')\n",
    "    Test_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 't10k')\n",
    "    #open(images_path)\n",
    "    print(Train_labels_path)\n",
    "    print(type(Train_labels_path))\n",
    "    with open(Train_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_train_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(Test_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_test_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "    with open(Train_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_train_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_train_orig), 784)\n",
    "    with open(Test_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_test_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_test_orig), 784)\n",
    "\n",
    "    return X_train_orig, Y_train_orig, X_test_orig, Y_test_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/train-labels.idx1-ubyte\n",
      "<class 'str'>\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(10, 60000)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(784, 10000)\n",
      "(10, 10000)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_mnist_data(path='MNIST_data/')\n",
    "print(X_train_orig.shape)\n",
    "print(Y_train_orig.shape)\n",
    "############\n",
    "X_train = X_train_orig.T/255\n",
    "Y_train_tensor = tf.one_hot(Y_train_orig, depth=10, axis=0)\n",
    "\n",
    "X_test = X_test_orig.T/255\n",
    "Y_test_tensor = tf.one_hot(Y_test_orig, depth=10, axis=0)\n",
    "#方法1\n",
    "with tf.Session() as sess: \n",
    "    # Run session and call the output \"result\"\n",
    "    Y_train =  sess.run(Y_train_tensor)\n",
    "    Y_test = sess.run(Y_test_tensor)\n",
    "#方法2\n",
    "Y_train2 = np.eye(10)[Y_train_orig.reshape(-1)].T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_train2.shape)\n",
    "print(Y_train2)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(type(Y_test_tensor))\n",
    "print(type(Y_test))\n",
    "print(type(X_test))\n",
    "\n",
    "print(parameters['W1'].shape)\n",
    "print(X_test.T[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22e77b67b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your algorithm predicts: Yhat = 8\n",
      "real class is Y = 4\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess your image to fit your algorithm.\n",
    "#fname = \"images/\" + my_image\n",
    "#image = np.array(ndimage.imread(fname, flatten=False))\n",
    "#my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "#my_image_prediction = predict(my_image, parameters)\n",
    "index2=4\n",
    "my_image_prediction = predict(X_test.T[index2].reshape(784, 1), parameters)\n",
    "\n",
    "\n",
    "#plt.imshow(image)\n",
    "plt.imshow(X_test.T[index2].reshape(28,28))\n",
    "plt.show()\n",
    "print(\"Your algorithm predicts: Yhat = \" + str(np.squeeze(my_image_prediction)))\n",
    "print(\"real class is Y = \"+ str(Y_test_orig[index2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
