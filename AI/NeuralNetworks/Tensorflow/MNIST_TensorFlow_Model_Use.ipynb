{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = tf.get_variable('W' + str(l) , [layer_dims[l], layer_dims[l-1]],  initializer = tf.contrib.layers.xavier_initializer(seed = 1))  #*0.01\n",
    "        parameters['b' + str(l)] = tf.get_variable('b' + str(l),[layer_dims[l], 1],  initializer = tf.zeros_initializer())\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "#     W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "#     W2 = tf.get_variable(\"W2\", [12, 25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "#     W3 = tf.get_variable(\"W3\", [6, 12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "#     b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_layer=[784,16,16,10]\n",
    "parameters = initialize_parameters(network_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
      "Model restored.\n",
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "[[-0.07698201 -0.08336387 -0.07433794 ... -0.03583223  0.00852627\n",
      "   0.02142677]\n",
      " [ 0.06581955  0.0486571   0.02417413 ...  0.08421017  0.05880846\n",
      "  -0.07478838]\n",
      " [-0.03511408  0.07325806 -0.00935223 ...  0.04019384  0.06981052\n",
      "  -0.04618645]\n",
      " ...\n",
      " [-0.04202675 -0.00866584  0.07966198 ... -0.03028224 -0.08036571\n",
      "  -0.00710306]\n",
      " [-0.00700899  0.03899312 -0.0460798  ...  0.07146367  0.0320491\n",
      "   0.00994988]\n",
      " [ 0.05764115 -0.05095618  0.03379001 ...  0.05744845  0.02907361\n",
      "  -0.04694676]]\n",
      "[[ 0.2601934 ]\n",
      " [ 0.4287062 ]\n",
      " [-0.19821462]\n",
      " [ 0.05104057]\n",
      " [ 0.05537603]\n",
      " [ 0.14086115]\n",
      " [-0.03804755]\n",
      " [ 0.00983803]\n",
      " [-0.05846215]\n",
      " [-0.46574205]\n",
      " [-0.20054515]\n",
      " [-0.06525063]\n",
      " [ 0.08595277]\n",
      " [ 0.26052377]\n",
      " [ 0.17321904]\n",
      " [-0.2825526 ]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "           # Run the initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    saver.restore(sess, \"./saved_model/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    print(type(parameters['W1']))\n",
    "    print(parameters['W1'].eval())\n",
    "    print(parameters['b1'].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3 }\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [X.shape[0], 1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "def load_mnist_data(path='MNIST_data/'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    Train_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 'train')\n",
    "    Train_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 'train')\n",
    "    Test_labels_path = os.path.join(path,'%s-labels.idx1-ubyte'% 't10k')\n",
    "    Test_images_path = os.path.join(path,'%s-images.idx3-ubyte'% 't10k')\n",
    "    #open(images_path)\n",
    "    print(Train_labels_path)\n",
    "    print(type(Train_labels_path))\n",
    "    with open(Train_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_train_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(Test_labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',lbpath.read(8))\n",
    "        Y_test_orig = np.fromfile(lbpath,dtype=np.uint8)\n",
    "\n",
    "    with open(Train_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_train_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_train_orig), 784)\n",
    "    with open(Test_images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))\n",
    "        X_test_orig = np.fromfile(imgpath,dtype=np.uint8).reshape(len(Y_test_orig), 784)\n",
    "\n",
    "    return X_train_orig, Y_train_orig, X_test_orig, Y_test_orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_data/train-labels.idx1-ubyte\n",
      "<class 'str'>\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(10, 60000)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(784, 10000)\n",
      "(10, 10000)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_mnist_data(path='MNIST_data/')\n",
    "print(X_train_orig.shape)\n",
    "print(Y_train_orig.shape)\n",
    "############\n",
    "X_train = X_train_orig.T/255\n",
    "Y_train_tensor = tf.one_hot(Y_train_orig, depth=10, axis=0)\n",
    "\n",
    "X_test = X_test_orig.T/255\n",
    "Y_test_tensor = tf.one_hot(Y_test_orig, depth=10, axis=0)\n",
    "#方法1\n",
    "with tf.Session() as sess: \n",
    "    # Run session and call the output \"result\"\n",
    "    Y_train =  sess.run(Y_train_tensor)\n",
    "    Y_test = sess.run(Y_test_tensor)\n",
    "#方法2\n",
    "Y_train2 = np.eye(10)[Y_train_orig.reshape(-1)].T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_train2.shape)\n",
    "print(Y_train2)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(type(Y_test_tensor))\n",
    "print(type(Y_test))\n",
    "print(type(X_test))\n",
    "\n",
    "print(parameters['W1'].shape)\n",
    "print(X_test.T[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwTziTb07AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c9cb71dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your algorithm predicts: Yhat = 5\n",
      "real class is Y = 7\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess your image to fit your algorithm.\n",
    "#fname = \"images/\" + my_image\n",
    "#image = np.array(ndimage.imread(fname, flatten=False))\n",
    "#my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "#my_image_prediction = predict(my_image, parameters)\n",
    "index2=0\n",
    "my_image_prediction = predict(X_test.T[index2].reshape(784, 1), parameters)\n",
    "\n",
    "\n",
    "#plt.imshow(image)\n",
    "plt.imshow(X_test.T[index2].reshape(28,28))\n",
    "plt.show()\n",
    "print(\"Your algorithm predicts: Yhat = \" + str(np.squeeze(my_image_prediction)))\n",
    "print(\"real class is Y = \"+ str(Y_test_orig[index2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16c9cb28400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your algorithm predicts: Yhat = 8\n",
      "real class is Y = 1\n"
     ]
    }
   ],
   "source": [
    "index2=3\n",
    "my_image_prediction = predict(X_test.T[index2].reshape(784, 1), parameters)\n",
    "\n",
    "\n",
    "#plt.imshow(image)\n",
    "plt.imshow(X_train.T[index2].reshape(28,28))\n",
    "plt.show()\n",
    "print(\"Your algorithm predicts: Yhat = \" + str(np.squeeze(my_image_prediction)))\n",
    "print(\"real class is Y = \"+ str(Y_train_orig[index2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
